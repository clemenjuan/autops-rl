<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Autonomous Decision-Making for Large Satellite Constellations: a Multi-Agent Reinforcement Learning Approach to Space Situational Awareness">
  <meta name="description" content="A decentralized multi-agent deep reinforcement learning approach for operating an autonomous Space Situational Awareness constellation of 20 satellites tracking 100 targets, achieving comparable or superior performance to centralized benchmarks with microsecond inference times.">
  <meta name="keywords" content="reinforcement learning, satellite coordination, multi-agent systems, PPO, autonomous systems, space systems, RL, MARL">
  <meta name="author" content="Clemente J. Juan Oliver">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="TUM - Chair of Spacecraft Systems">
  <meta property="og:title" content="Autonomous Decision-Making for Large Satellite Constellations: a Multi-Agent Reinforcement Learning Approach to Space Situational Awareness">
  <meta property="og:description" content="A decentralized multi-agent deep reinforcement learning approach for operating an autonomous Space Situational Awareness constellation of 20 satellites tracking 100 targets, achieving comparable or superior performance to centralized benchmarks with microsecond inference times.">
  <meta property="og:url" content="https://clemenjuan.github.io/autops-rl/">
  <meta property="og:image" content="https://clemenjuan.github.io/autops-rl/static/images/example_constellation.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="AUTOPS-RL: Autonomous Satellite Coordination with Reinforcement Learning">
  <meta property="article:published_time" content="2025-01-01T00:00:00.000Z">
  <meta property="article:author" content="Clemente J. Juan Oliver">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Reinforcement Learning">
  <meta property="article:tag" content="Satellite Coordination">


  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Autonomous Decision-Making for Large Satellite Constellations: a Multi-Agent Reinforcement Learning Approach to Space Situational Awareness in Partially Observable Dynamic Environments">
  <meta name="citation_author" content="Juan Oliver, Clemente J.">
  <meta name="citation_author" content="Messina, Vincenzo">
  <meta name="citation_author" content="Dolan, Sydney">
  <meta name="citation_author" content="Golkar, Alessandro">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="EUCASS 2025">
  <meta name="citation_pdf_url" content="https://clemenjuan.github.io/autops-rl/static/pdfs/EUCASS2025-248.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>Autonomous Decision-Making for Large Satellite Constellations: Multi-Agent RL for Space Situational Awareness | TUM</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "SoftwareSourceCode",
    "name": "AUTOPS-RL",
    "description": "A reinforcement learning framework for autonomous satellite coordination and real-time decision-making using multi-agent PPO",
    "author": {
      "@type": "Person",
      "name": "Clemente J. Juan Oliver",
      "affiliation": {
        "@type": "Organization",
        "name": "Technical University of Munich, Chair of Spacecraft Systems"
      }
    },
    "datePublished": "2025-01-01",
    "codeRepository": "https://github.com/clemenjuan/autops-rl",
    "url": "https://clemenjuan.github.io/autops-rl/",
    "image": "https://clemenjuan.github.io/autops-rl/static/images/social_preview.png",
    "keywords": ["reinforcement learning", "satellite coordination", "multi-agent systems", "PPO", "autonomous systems"],
    "programmingLanguage": "Python",
    "license": "https://opensource.org/licenses/MIT",
    "isAccessibleForFree": true
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Chair of Spacecraft Systems, TUM",
    "url": "https://www.asg.ed.tum.de/en/sps/home/",
    "logo": "https://clemenjuan.github.io/autops-rl/static/images/favicon.ico",
    "sameAs": [
      "https://github.com/clemenjuan"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Autonomous Decision-Making for Large Satellite Constellations: a Multi-Agent Reinforcement Learning Approach to Space Situational Awareness in Partially Observable Dynamic Environments</h1>
            <div class="is-size-6 publication-authors" style="margin-top: 1rem;">
              <span class="author-block">
                <a href="https://www.linkedin.com/in/clemente-juan-oliver/" target="_blank">Clemente J. Juan Oliver</a>,
                <a href="https://www.asg.ed.tum.de/en/sps/mitarbeiter/vincenzo-messina/" target="_blank">Vincenzo Messina</a>,
                <a href="https://sydneyidolan.com/" target="_blank">Sydney Dolan</a>,
                <a href="https://www.professoren.tum.de/en/golkar-alessandro" target="_blank">Alessandro Golkar</a>
              </span>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.5rem; color: #666;">
              <span class="author-block">
                <a href="https://www.asg.ed.tum.de/en/sps/home/" target="_blank" style="color: #666;">Technical University of Munich (TUM), Chair of Spacecraft Systems</a>
              </span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                <span class="link-block">
                  <a href="https://gitlab.lrz.de/sps/autops/autops-rl" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-gitlab"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

                <span class="link-block">
                  <a href="static/pdfs/EUCASS2025-248.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Traditional centralized operations struggle to scale with the complexity of large satellite constellations. This work presents 
            a decentralized multi-agent deep reinforcement learning approach for operating an autonomous Space Situational Awareness constellation 
            of 20 satellites. Four reward functions, with different reward scaling factors, are evaluated using a mission goal term across three 
            coordination topologies. Developed strategies obtain similar or even outperform centralized rule-based and Mixed Integer Programming 
            benchmarks in tested scenarios, and generalize across coordination topologies despite being trained in fully decentralized environments. 
            Finally, space hardware inference confirms feasibility in modern systems, with execution times in the microsecond range.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Methodology Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Methodology</h2>
    <div class="columns">
      <div class="column is-half">
        <div class="content">
          <h3 class="title is-4">Multi-Agent Reinforcement Learning</h3>
          <p>
            AUTOPS-RL uses distributed Proximal Policy Optimization (PPO) to train coordination policies for multiple observer satellites. 
            Each satellite acts as an independent agent making real-time decisions about which targets to observe, considering battery constraints, 
            communication limitations, and mission objectives.
          </p>
          <h3 class="title is-4">Network Architectures</h3>
          <ul>
            <li><strong>Centralized:</strong> Full information sharing with global coordination</li>
            <li><strong>Constrained Decentralized:</strong> Limited communication range with local coordination</li>
            <li><strong>Fully Decentralized:</strong> No communication, independent decision-making</li>
          </ul>
        </div>
      </div>
      <div class="column is-half">
        <div class="content">
          <h3 class="title is-4">Reward Function Design</h3>
          <p>Four reward cases evaluated:</p>
          <ul>
            <li><strong>Case 1:</strong> Positive rewards for observed targets (individual)</li>
            <li><strong>Case 2:</strong> Negative rewards for unobserved targets (individual)</li>
            <li><strong>Case 3:</strong> Individual rewards + global bonus for observed targets (collective)</li>
            <li><strong>Case 4:</strong> Individual rewards + global bonus for unobserved targets (collective)</li>
          </ul>
          <h3 class="title is-4">Sensitivity Analysis</h3>
          <p>
            Comprehensive evaluation across 6 scaling factors (α = 0.0, 0.01, 0.05, 1.0, 2.0, 5.0) to analyze 
            the impact of reward scaling on policy performance and coordination behavior.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Constellation Visualization -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Constellation Configuration Example</h2>
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="content has-text-centered">
          <img class="zoomable-image" src="static/images/example_constellation.png" alt="Satellite constellation visualization showing 20 observer satellites in Walker Delta formation tracking 100 target objects" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); cursor: zoom-in;">
          <p class="has-text-centered" style="margin-top: 1rem;">
            <strong>Space Situational Awareness Scenario:</strong> 20 observer satellites arranged in a Walker Delta constellation 
            coordinate to track and monitor 100 target objects in various orbital configurations. Each observer satellite must 
            autonomously decide which targets to observe while managing battery constraints and communication limitations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Results</h2>
    
    <div class="columns">
      <div class="column is-one-third">
        <div class="content">
          <h3 class="title is-5 has-text-centered">Mission Accomplishment</h3>
          <img class="zoomable-image" src="static/images/mission_accomplishment_boxplot.png" alt="Mission accomplishment comparison across different methods and scaling factors" style="width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;">
          <p class="has-text-justified is-size-7" style="margin-top: 0.75rem;">
            Comparison of mission accomplishment rates across RL policies (with different scaling factors), rule-based, and MIP baseline methods. 
            Results show the effectiveness of learned coordination strategies compared to traditional approaches.
          </p>
        </div>
      </div>
      <div class="column is-one-third">
        <div class="content">
          <h3 class="title is-5 has-text-centered">Resource Utilization</h3>
          <img class="zoomable-image" src="static/images/resource_utilization_boxplot.png" alt="Resource utilization efficiency across different methods" style="width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;">
          <p class="has-text-justified is-size-7" style="margin-top: 0.75rem;">
            Analysis of resource utilization efficiency, including battery consumption and observation coverage. 
            RL policies demonstrate efficient resource management while maintaining high mission performance.
          </p>
        </div>
      </div>
      <div class="column is-one-third">
        <div class="content">
          <h3 class="title is-5 has-text-centered">Action Distribution Analysis</h3>
          <img class="zoomable-image" src="static/images/action_distribution_analysis.png" alt="Action distribution analysis showing decision patterns across different policies" style="width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;">
          <p class="has-text-justified is-size-7" style="margin-top: 0.75rem;">
            Detailed breakdown of action distributions across different policies, revealing coordination patterns and decision-making 
            strategies learned by the RL agents compared to rule-based and optimization-based approaches.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Key Findings Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Key Findings</h2>
    <div class="columns">
      <div class="column is-one-third">
        <div class="content has-text-centered">
          <div class="box" style="height: 100%;">
            <h3 class="title is-4">Performance</h3>
            <p class="is-size-5 has-text-weight-bold" style="color: #2563eb;">60-70%</p>
            <p>Remaining resources maintained across all coordination topologies, demonstrating efficient resource management while maintaining high mission performance.</p>
          </div>
        </div>
      </div>
      <div class="column is-one-third">
        <div class="content has-text-centered">
          <div class="box" style="height: 100%;">
            <h3 class="title is-4">Inference Speed</h3>
            <p class="is-size-5 has-text-weight-bold" style="color: #2563eb;">~4μs</p>
            <p>Average inference time per decision on NVIDIA Jetson Orin Nano (7W power mode), confirming real-time feasibility for onboard deployment.</p>
          </div>
        </div>
      </div>
      <div class="column is-one-third">
        <div class="content has-text-centered">
          <div class="box" style="height: 100%;">
            <h3 class="title is-4">Generalization</h3>
            <p class="is-size-5 has-text-weight-bold" style="color: #2563eb;">Cross-Topology</p>
            <p>Policies trained in fully decentralized environments generalize effectively to centralized and constrained decentralized topologies, demonstrating robust coordination strategies.</p>
          </div>
        </div>
      </div>
    </div>
    <div class="columns" style="margin-top: 1rem;">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            <strong>Hardware Validation:</strong> The trained policies were evaluated on an NVIDIA Jetson Orin Nano operating in 7W power mode, 
            a configuration specifically designed for resource-constrained applications. This computing platform has been identified as a promising 
            candidate for AI-enabled nanosatellite missions due to its balance of size, computational capability, and power efficiency. The empirical 
            results demonstrate that the developed neural network policies can be executed in real-time on low-power onboard systems without 
            compromising mission-critical response times.
          </p>
          <p style="margin-top: 1rem;">
            <strong>Reward Function Insights:</strong> Negative reward functions maintain more balanced operational modes even under communication 
            limitations, with observation activities remaining above 20% in constrained scenarios. This aligns with research suggesting that shifting 
            reward functions towards values equal to or lower than zero leads to faster convergence and better optimal decisions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Training Curves Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Training Performance</h2>
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content has-text-centered">
          <img class="zoomable-image" src="static/images/professional_training_curves_all_alpha.png" alt="Training curves showing learning progress across different scaling factors" style="width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); cursor: zoom-in;">
          <p class="has-text-justified" style="margin-top: 1rem;">
            Training curves demonstrating learning progress across all reward cases and scaling factors. The plots show convergence 
            behavior, sample efficiency, and final performance levels achieved by the distributed PPO training process. Negative reward 
            functions demonstrate superior stability and robustness in resource-constrained, mission-critical environments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>











<!-- Paper PDF -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Paper</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-centered">
            <p class="is-size-5" style="margin-bottom: 1.5rem;">
              <strong>EUCASS 2025</strong> - 11th European Conference for Aeronautics and Aerospace Sciences (EUCASS)
            </p>
            <iframe src="static/pdfs/EUCASS2025-248.pdf" width="100%" height="800" style="border-radius: 8px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
            </iframe>
            <p style="margin-top: 1rem;">
              <a href="static/pdfs/EUCASS2025-248.pdf" target="_blank" class="button is-primary">
                <span class="icon"><i class="fas fa-download"></i></span>
                <span>Download PDF</span>
              </a>
              <a href="https://www.eucass.eu/component/docindexer/?task=download&id=7581" target="_blank" class="button is-info" style="margin-left: 0.5rem;">
                <span class="icon"><i class="fas fa-external-link-alt"></i></span>
                <span>View on EUCASS</span>
              </a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End paper PDF -->

<!-- Presentation -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Presentation</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div class="content has-text-centered">
            <p class="is-size-5" style="margin-bottom: 1.5rem;">
              <strong>EUCASS 2025</strong> - Conference Presentation Slides
            </p>
            <div style="margin-bottom: 1.5rem;">
              <a href="static/presentations/Clemente_Juan_EUCASS_2025_public.pptx" target="_blank" class="button is-primary is-large">
                <span class="icon"><i class="fas fa-file-powerpoint"></i></span>
                <span>Download Presentation (PowerPoint)</span>
              </a>
            </div>
            <p class="has-text-justified">
              Download the conference presentation slides from EUCASS 2025. The presentation covers the methodology, 
              experimental setup, results, and key findings of the AUTOPS-RL framework for autonomous satellite coordination.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End presentation -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{autops-rl2025,
  title={Autonomous Decision-Making for Large Satellite Constellations: a Multi-Agent Reinforcement Learning Approach to Space Situational Awareness in Partially Observable Dynamic Environments},
  author={Juan Oliver, Clemente J. and Messina, Vincenzo and Dolan, Sydney and Golkar, Alessandro},
  booktitle={11th European Conference for Aeronautics and Aerospace Sciences (EUCASS)},
  year={2025},
  url={https://gitlab.lrz.de/sps/autops/autops-rl},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
